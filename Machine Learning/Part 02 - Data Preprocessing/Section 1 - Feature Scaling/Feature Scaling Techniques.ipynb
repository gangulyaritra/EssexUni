{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Scaling Techniques.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9iktAAKqIZX"
      },
      "source": [
        "# **Feature Transformation and Scaling Techniques.**\n",
        "\n",
        "Feature Scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is performed during the data preprocessing step.\n",
        "\n",
        "[Importance of Feature Scaling](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html)\n",
        "\n",
        "[sklearn.preprocessing: Preprocessing and Normalization](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n",
        "\n",
        "[Feature Scaling Techniques](https://www.analyticsvidhya.com/blog/2020/07/types-of-feature-transformation-and-scaling/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "TbeMlD2YsxMv",
        "outputId": "9127c894-6a1e-46e8-8382-13ab6747eafe"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"CE802_Ass_2019_Data.csv\") # Load Dataset.\n",
        "data = data.iloc[:, :-2]\n",
        "data"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>2.02</td>\n",
              "      <td>0.52</td>\n",
              "      <td>-2.35</td>\n",
              "      <td>-1.98</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>85</td>\n",
              "      <td>6</td>\n",
              "      <td>-2.07</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>1.08</td>\n",
              "      <td>15</td>\n",
              "      <td>-0.63</td>\n",
              "      <td>-3.49</td>\n",
              "      <td>-1.68</td>\n",
              "      <td>0.02</td>\n",
              "      <td>15.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>2.75</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.83</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>107</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.86</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.06</td>\n",
              "      <td>-8</td>\n",
              "      <td>-1.21</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.61</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>165</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.05</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-1.65</td>\n",
              "      <td>41</td>\n",
              "      <td>5</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.42</td>\n",
              "      <td>-6</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>1.67</td>\n",
              "      <td>2.60</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>191</td>\n",
              "      <td>-1.50</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.33</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.35</td>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.74</td>\n",
              "      <td>15</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>6.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.22</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>0.68</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>1.25</td>\n",
              "      <td>25</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>-2.41</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>10.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>138</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.05</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.87</td>\n",
              "      <td>36</td>\n",
              "      <td>16</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>0.70</td>\n",
              "      <td>23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>-1.24</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>1.26</td>\n",
              "      <td>20.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102</td>\n",
              "      <td>2.06</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.84</td>\n",
              "      <td>3.63</td>\n",
              "      <td>1.22</td>\n",
              "      <td>57</td>\n",
              "      <td>-2</td>\n",
              "      <td>-0.32</td>\n",
              "      <td>-0.38</td>\n",
              "      <td>0.56</td>\n",
              "      <td>-6</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>-1.29</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.47</td>\n",
              "      <td>19.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>211</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1.16</td>\n",
              "      <td>47</td>\n",
              "      <td>-49</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>0.78</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.45</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>-0.86</td>\n",
              "      <td>1.06</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.25</td>\n",
              "      <td>23</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-8</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.58</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>-1.20</td>\n",
              "      <td>6.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>104</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.72</td>\n",
              "      <td>-1.41</td>\n",
              "      <td>3.46</td>\n",
              "      <td>0.54</td>\n",
              "      <td>31</td>\n",
              "      <td>-19</td>\n",
              "      <td>0.92</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>1.84</td>\n",
              "      <td>-13</td>\n",
              "      <td>1.37</td>\n",
              "      <td>-1.56</td>\n",
              "      <td>0.11</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>18.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     F1  F2   F3    F4    F5    F6  ...  F14   F15   F16   F17   F18   F19\n",
              "0     0   0   16  2.02  0.52 -2.35  ...   15 -0.63 -3.49 -1.68  0.02  15.3\n",
              "1     0   0   86 -0.90  2.75  0.14  ...   -8 -1.21  0.34  0.36  0.61  10.1\n",
              "2     1   1  165  0.73  1.05  0.10  ...   -6 -0.46 -0.62  1.67  2.60  11.0\n",
              "3     1   1  191 -1.50  0.79  0.33  ...   15  0.47  0.63  0.08  0.19   6.3\n",
              "4     1   1   13  0.25 -1.19 -0.90  ...   25 -0.09 -2.41 -0.53 -0.77  10.5\n",
              "..   ..  ..  ...   ...   ...   ...  ...  ...   ...   ...   ...   ...   ...\n",
              "495   1   1  138  1.36  0.40  1.05  ...   23  0.23 -1.24 -0.65  1.26  20.9\n",
              "496   0   0  102  2.06  0.09  0.84  ...   -6 -0.08 -1.29 -0.03  0.47  19.6\n",
              "497   1   0  211  0.18  1.71  0.30  ...    7 -0.27 -0.45 -0.89  0.00   5.9\n",
              "498   1   0   94 -0.86  1.06  0.66  ...   -8  0.42  1.58 -0.79 -1.20   6.4\n",
              "499   1   1  104  0.23  1.72 -1.41  ...  -13  1.37 -1.56  0.11 -0.01  18.3\n",
              "\n",
              "[500 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgSaFBpZumLm",
        "outputId": "c1a62f1b-8173-4cc6-adb3-2a5d2d9ddd9d"
      },
      "source": [
        "data.info() # Data Summary."
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 19 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   F1      500 non-null    int64  \n",
            " 1   F2      500 non-null    int64  \n",
            " 2   F3      500 non-null    int64  \n",
            " 3   F4      500 non-null    float64\n",
            " 4   F5      500 non-null    float64\n",
            " 5   F6      500 non-null    float64\n",
            " 6   F7      500 non-null    float64\n",
            " 7   F8      500 non-null    float64\n",
            " 8   F9      500 non-null    int64  \n",
            " 9   F10     500 non-null    int64  \n",
            " 10  F11     500 non-null    float64\n",
            " 11  F12     500 non-null    float64\n",
            " 12  F13     500 non-null    float64\n",
            " 13  F14     500 non-null    int64  \n",
            " 14  F15     500 non-null    float64\n",
            " 15  F16     500 non-null    float64\n",
            " 16  F17     500 non-null    float64\n",
            " 17  F18     500 non-null    float64\n",
            " 18  F19     500 non-null    float64\n",
            "dtypes: float64(13), int64(6)\n",
            "memory usage: 74.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cggASHTUrVrv"
      },
      "source": [
        "# **Normalization (MinMax Scaler)**\n",
        "\n",
        "[sklearn.preprocessing.MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler)\n",
        "\n",
        "Transform features by scaling each feature to a given range. MinMaxScaler estimator scales and translates each feature individually such that it is in the given range on the training set, i.e., between 0 and 1.\n",
        "\n",
        "> # **$X_{Scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}$**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZUBZK-LouH0",
        "outputId": "f07e6529-d36b-411e-e260-8102fffbcd6f"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.03880597, ..., 0.24295775, 0.46998536,\n",
              "        0.4077135 ],\n",
              "       [0.        , 0.        , 0.24776119, ..., 0.60211268, 0.55636896,\n",
              "        0.26446281],\n",
              "       [1.        , 1.        , 0.48358209, ..., 0.83274648, 0.8477306 ,\n",
              "        0.2892562 ],\n",
              "       ...,\n",
              "       [1.        , 0.        , 0.62089552, ..., 0.38204225, 0.4670571 ,\n",
              "        0.14876033],\n",
              "       [1.        , 0.        , 0.27164179, ..., 0.39964789, 0.29136164,\n",
              "        0.16253444],\n",
              "       [1.        , 1.        , 0.30149254, ..., 0.55809859, 0.46559297,\n",
              "        0.49035813]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL45lkjxvkul"
      },
      "source": [
        "# **Standardization (Standard Scaler)**\n",
        "\n",
        "[sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler)\n",
        "\n",
        "Standardize features by removing the mean (i.e., mean = 0) and scaling to unit variance. The standard score of is calculated as:\n",
        "\n",
        "> # **$Z = \\frac{X - \\mu}{\\sigma}$**\n",
        "\n",
        "where $\\mu$ is the mean of the training samples and $\\sigma$ is the standard deviation of the training samples.\n",
        "\n",
        "Centering and Scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Both mean and standard deviation are then stored to be used on later data using transform.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC2W7UMf0lVb",
        "outputId": "12b29e46-bceb-4c99-beef-8d192abe2403"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.41846685, -1.01207287, -1.09898488, ..., -1.64115528,\n",
              "         0.1034851 ,  1.03416374],\n",
              "       [-1.41846685, -1.01207287, -0.10254763, ...,  0.44259201,\n",
              "         0.69442788,  0.13875406],\n",
              "       [ 0.70498652,  0.98807114,  1.02200299, ...,  1.78068464,\n",
              "         2.68760777,  0.29372881],\n",
              "       ...,\n",
              "       [ 0.70498652, -1.01207287,  1.67680461, ..., -0.83421393,\n",
              "         0.08345314, -0.58446145],\n",
              "       [ 0.70498652, -1.01207287,  0.01133092, ..., -0.73206945,\n",
              "        -1.11846438, -0.49836437],\n",
              "       [ 0.70498652,  0.98807114,  0.15367909, ...,  0.18723082,\n",
              "         0.07343716,  1.55074625]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kQYYYib1uE6"
      },
      "source": [
        "# **MaxAbsScaler**\n",
        "\n",
        "[sklearn.preprocessing.MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler)\n",
        "\n",
        "Scale each feature by its maximum absolute value. That is, the MaxAbs scaler takes the absolute maximum value of each column and divides each value in the column by the maximum value. This operation scales the data between the range [-1, +1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJhCObF6BQZO",
        "outputId": "b86a7190-1b9f-4027-c266-0a1af530fb00"
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "scaler = MaxAbsScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.04733728, ..., -0.54901961,\n",
              "         0.00549451,  0.41576087],\n",
              "       [ 0.        ,  0.        ,  0.25443787, ...,  0.11764706,\n",
              "         0.16758242,  0.27445652],\n",
              "       [ 1.        ,  1.        ,  0.48816568, ...,  0.54575163,\n",
              "         0.71428571,  0.29891304],\n",
              "       ...,\n",
              "       [ 1.        ,  0.        ,  0.62426036, ..., -0.29084967,\n",
              "         0.        ,  0.16032609],\n",
              "       [ 1.        ,  0.        ,  0.27810651, ..., -0.25816993,\n",
              "        -0.32967033,  0.17391304],\n",
              "       [ 1.        ,  1.        ,  0.30769231, ...,  0.03594771,\n",
              "        -0.00274725,  0.49728261]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1iRmQ8ECUYM"
      },
      "source": [
        "# **Robust Scaler**\n",
        "\n",
        "[sklearn.preprocessing.RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)\n",
        "\n",
        "**Scale features using statistics that are robust to outliers.**\n",
        "\n",
        "In the previous feature scaling techniques, each of the methods was using values like the mean, maximum and minimum values of the features. All these above feature scaling techniques are sensitive to outliers. If there are too many outliers in the data, then these outliers will influence the mean and the maximum value or the minimum value. Thus, even if we scale the data using the above methods, we cannot guarantee a balanced data with a normal distribution.\n",
        "\n",
        "> # **$X_{Scaled} = \\frac{X - Q1}{Q3 - Q1}$**\n",
        "\n",
        "The Inter-Quartile Range $IQR$ is the difference between the first and third quartile of the variable. The Inter-Quartile Range can be defined as $IQR = Q3 - Q1$\n",
        "\n",
        "This Scaler removes the median and scales the data according to the quantile range (defaults to $IQR$: Inter-Quartile Range). The $IQR$ is the range between the $1^{st}$ quartile ($25^{th}$ quantile) and the $3^{rd}$ quartile ($75^{th}$ quantile).\n",
        "\n",
        "**The Robust Scaler is not sensitive to outliers.**\n",
        "\n",
        "1.   Robust Scaler removes the median from the data.\n",
        "2.   Robust Scaler scales the data by the Inter-Quartile Range ($IQR$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beuo36BMCgmk",
        "outputId": "65caf79c-446d-4eea-b788-5e63356808cd"
      },
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "scaler = RobustScaler()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.        , -1.        , -0.64122137, ..., -1.20930233,\n",
              "         0.08921933,  1.05970149],\n",
              "       [-1.        , -1.        ,  0.07124682, ...,  0.37209302,\n",
              "         0.52788104,  0.28358209],\n",
              "       [ 0.        ,  0.        ,  0.87531807, ...,  1.3875969 ,\n",
              "         2.00743494,  0.41791045],\n",
              "       ...,\n",
              "       [ 0.        , -1.        ,  1.34351145, ..., -0.59689922,\n",
              "         0.07434944, -0.34328358],\n",
              "       [ 0.        , -1.        ,  0.15267176, ..., -0.51937984,\n",
              "        -0.81784387, -0.26865672],\n",
              "       [ 0.        ,  0.        ,  0.25445293, ...,  0.17829457,\n",
              "         0.0669145 ,  1.50746269]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr5vHQbBNSMx"
      },
      "source": [
        "# **Quantile Transformer Scaler**\n",
        "\n",
        "[sklearn.preprocessing.QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer)\n",
        "\n",
        "**Transform features using quantiles information.**\n",
        "\n",
        "The Quantile Transformer Scaler converts the variable distribution to a normal distribution and scales it accordingly. Since it makes the variable normally distributed, it also deals with the outliers.\n",
        "\n",
        "This method transforms the features to follow a uniform or a normal distribution. Therefore, for a given feature, this transformation tends to spread out the most frequent values. It also reduces the impact of (marginal) outliers, i.e., this is a robust preprocessing scheme. The transformation is applied to each feature independently.\n",
        "\n",
        "A few points regarding the Quantile Transformer Scaler:\n",
        "\n",
        "1.   It computes the cumulative distribution function of the variable.\n",
        "2.   It uses the cumulative distribution function to map the values to a normal distribution.\n",
        "3.   Maps the obtained values to the desired output distribution using the associated quantile function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKNQqA_jRS2P",
        "outputId": "e81aa0f8-541e-4553-a2b1-7bd636ec0828"
      },
      "source": [
        "from sklearn.preprocessing import QuantileTransformer\n",
        "scaler = QuantileTransformer()\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:2357: UserWarning: n_quantiles (1000) is greater than the total number of samples (500). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.09418838, ..., 0.04408818, 0.55711423,\n",
              "        0.87775551],\n",
              "       [0.        , 0.        , 0.53507014, ..., 0.66432866, 0.75350701,\n",
              "        0.63827655],\n",
              "       [1.        , 1.        , 0.84168337, ..., 0.95591182, 0.99398798,\n",
              "        0.69639279],\n",
              "       ...,\n",
              "       [1.        , 0.        , 0.9258517 , ..., 0.18937876, 0.55310621,\n",
              "        0.30961924],\n",
              "       [1.        , 0.        , 0.58116232, ..., 0.22344689, 0.13827655,\n",
              "        0.34669339],\n",
              "       [1.        , 1.        , 0.64729459, ..., 0.58917836, 0.54609218,\n",
              "        0.91583166]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km8Q4aAThI5F"
      },
      "source": [
        "# **Power Transformer Scaler**\n",
        "\n",
        "[sklearn.preprocessing.PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer)\n",
        "\n",
        "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance) or other situations where normality is desired.\n",
        "\n",
        "At present, PowerTransformer supports the Box-Cox transform and the Yeo-Johnson transform. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A48_IWs7hqAs",
        "outputId": "656c247a-9b7d-43c5-fc58-b543ac080244"
      },
      "source": [
        "from sklearn.preprocessing import PowerTransformer\n",
        "scaler = PowerTransformer(method = 'yeo-johnson')\n",
        "'''\n",
        "parameters: method = 'box-cox' or 'yeo-johnson'\n",
        "'''\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.41846685, -1.01207287, -1.39729118, ..., -1.67602682,\n",
              "         0.13492508,  1.11371656],\n",
              "       [-1.41846685, -1.01207287,  0.16056943, ...,  0.45863061,\n",
              "         0.71044795,  0.38365554],\n",
              "       [ 0.70498652,  0.98807114,  1.05221182, ...,  1.74191575,\n",
              "         2.53940344,  0.5296906 ],\n",
              "       ...,\n",
              "       [ 0.70498652, -1.01207287,  1.44309475, ..., -0.83108089,\n",
              "         0.11496598, -0.48435394],\n",
              "       [ 0.70498652, -1.01207287,  0.27099103, ..., -0.72544269,\n",
              "        -1.13267158, -0.35902027],\n",
              "       [ 0.70498652,  0.98807114,  0.40061656, ...,  0.20687762,\n",
              "         0.10497309,  1.44306524]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}