{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter Optimization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bea05d72077946bd85341606a6167bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c1736d7b97a4d7990b45b95889e9afa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_401051a0b8544e15877fca09e4ef46ed",
              "IPY_MODEL_804d1cf3b44f446093239c32ab558f76"
            ]
          }
        },
        "4c1736d7b97a4d7990b45b95889e9afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "401051a0b8544e15877fca09e4ef46ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_792908175e804b3d8ee4d1644ce9af5a",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 84,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 84,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e6d938608bc4570a4dc65cc5e68d089"
          }
        },
        "804d1cf3b44f446093239c32ab558f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_624099d88b79485c935e2840c842faf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 84/84 [37:39&lt;00:00, 40.55s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ba1b10fc68f43a6b1f6e69a953c45d9"
          }
        },
        "792908175e804b3d8ee4d1644ce9af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e6d938608bc4570a4dc65cc5e68d089": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "624099d88b79485c935e2840c842faf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ba1b10fc68f43a6b1f6e69a953c45d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZo1mGpqa-kX"
      },
      "source": [
        "# **Hyperparameter Optimization**\n",
        "\n",
        "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\n",
        "\n",
        "The same kind of machine learning model can require different constraints, weights, or learning rates to generalize different data patterns. These measures are called hyperparameters and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data. The objective function takes a tuple of hyperparameters and returns the associated loss. Cross-validation is often used to estimate this generalization performance.\n",
        "\n",
        "[Hyperparameter Optimization - Wikipedia](https://en.wikipedia.org/wiki/Hyperparameter_optimization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGhXd7ypJydx"
      },
      "source": [
        "# Import Library.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "KwdniPYuKxDT",
        "outputId": "497950a7-ca62-460a-de52-521e3b80af80"
      },
      "source": [
        "data = pd.read_csv('diabetes.csv')  # Load Dataset.\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWVGBjyeLIcs",
        "outputId": "3ae95e03-c839-498f-e001-1f488c5152e5"
      },
      "source": [
        "data.info() # Dataset Summary."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 9 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Pregnancies               768 non-null    int64  \n",
            " 1   Glucose                   768 non-null    int64  \n",
            " 2   BloodPressure             768 non-null    int64  \n",
            " 3   SkinThickness             768 non-null    int64  \n",
            " 4   Insulin                   768 non-null    int64  \n",
            " 5   BMI                       768 non-null    float64\n",
            " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
            " 7   Age                       768 non-null    int64  \n",
            " 8   Outcome                   768 non-null    int64  \n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 54.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75UZA3IBVH5O"
      },
      "source": [
        "# **Exploratory Data Analysis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbEiVg2tNugh"
      },
      "source": [
        "sns.pairplot(data, hue = 'Outcome')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tEnLlANN6ao"
      },
      "source": [
        "# Split the dataset into features and target value.\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "\n",
        "# Feature Scaling.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "# Split the dataset into training and test set.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi3b-q9kO-m6"
      },
      "source": [
        "# **Using Random Forest Classifier.**\n",
        "\n",
        "[sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
        "\n",
        "\n",
        "The main parameters used by a Random Forest Classifier are:\n",
        "\n",
        "\n",
        "*   **criterion** = the function used to evaluate the quality of a split.\n",
        "*   **max_depth** = maximum number of levels allowed in each tree.\n",
        "*   **max_features** = maximum number of features considered when splitting a node.\n",
        "*   **min_samples_leaf** = minimum number of samples which can be stored in a tree leaf.\n",
        "*   **min_samples_split** = minimum number of samples necessary in a node to cause node splitting.\n",
        "*   **n_estimators** = number of trees in the ensamble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbj381QbPAcw"
      },
      "source": [
        "# Using Random Forest, with manual Hyperparameter Optimization.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators = 300, criterion = 'entropy', max_features = 'sqrt', min_samples_leaf = 10, random_state = 100)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set results.\n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeZiOXbxXU7Z",
        "outputId": "e4aab268-14e9-4ed7-e3b3-be8a2f3a4305"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(\"Accuracy Score is \", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score is  0.78125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.92      0.85       130\n",
            "           1       0.75      0.48      0.59        62\n",
            "\n",
            "    accuracy                           0.78       192\n",
            "   macro avg       0.77      0.70      0.72       192\n",
            "weighted avg       0.78      0.78      0.77       192\n",
            "\n",
            "[[120  10]\n",
            " [ 32  30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9hB7WCgX2go"
      },
      "source": [
        "# **Grid Search**\n",
        "\n",
        "[sklearn.model_selection.GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "\n",
        "\n",
        "The traditional way of performing hyperparameter optimization has been Grid Search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm. A Grid Search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set. Since the parameter space of a machine learner may include real-valued or unbounded value spaces for certain parameters, manually set bounds, and discretization may be necessary before applying grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fEru-A1X5l-",
        "outputId": "c0237f24-1ed1-409c-c067-37323675282a"
      },
      "source": [
        "# Hyperparameter Optimization.\n",
        "\n",
        "parameters = {\n",
        " \"n_estimators\"       : [100, 200, 300],   # Number of trees in Random Forest.\n",
        " \"criterion\"          : ['entropy','gini'],\n",
        " \"max_depth\"          : [None, 1, 3, 5],    # Maximum number of levels in the tree.\n",
        " \"min_samples_split\"  : [2, 3, 5],   # Minimum number of samples required to split a node.\n",
        " \"max_features\"       : ['auto', 'sqrt','log2'],  # Number of features to consider at every split.\n",
        " \"min_samples_leaf\"   : [1, 2, 4]  # Minimum number of samples required at each leaf node.\n",
        "}\n",
        "\n",
        "print(parameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 200, 300], 'criterion': ['entropy', 'gini'], 'max_depth': [None, 1, 3, 5], 'min_samples_split': [2, 3, 5], 'max_features': ['auto', 'sqrt', 'log2'], 'min_samples_leaf': [1, 2, 4]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj_8Ox3UchJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97982d10-c424-4a80-fde8-6e501308d970"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "clf = RandomForestClassifier()\n",
        "grid_search = GridSearchCV(estimator = clf, param_grid = parameters, cv = 10, n_jobs = -1, verbose = 2)\n",
        "grid_search = grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 648 candidates, totalling 6480 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   50.7s\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed:  9.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 15.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 19.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 22.3min\n",
            "[Parallel(n_jobs=-1)]: Done 5828 tasks      | elapsed: 26.3min\n",
            "[Parallel(n_jobs=-1)]: Done 6480 out of 6480 | elapsed: 29.2min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDGPKpfldUuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468a4ff7-228b-400b-bf9c-b74c3b246919"
      },
      "source": [
        "best_grid = grid_search.best_estimator_\n",
        "print(grid_search.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=4, min_samples_split=5,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbXbhKdadcyU"
      },
      "source": [
        "y_pred = best_grid.predict(X_test)  # Predicting the test set results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCfnFqpoemLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd47e603-b3e9-4421-e83b-687289ae1fbb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.796875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.91      0.86       130\n",
            "           1       0.74      0.56      0.64        62\n",
            "\n",
            "    accuracy                           0.80       192\n",
            "   macro avg       0.78      0.74      0.75       192\n",
            "weighted avg       0.79      0.80      0.79       192\n",
            "\n",
            "[[118  12]\n",
            " [ 27  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fx4o1aFRp-5"
      },
      "source": [
        "# **Random Search**\n",
        "\n",
        "[sklearn.model_selection.RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "\n",
        "\n",
        "Random Search replaces the exhaustive enumeration of all combinations by selecting them randomly. This can be simply applied to the discrete setting described above, but also generalizes to continuous and mixed spaces. It can outperform Grid Search, especially when only a small number of hyperparameters affects the final performance of the machine learning algorithm [[1]](https://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf). In this case, the optimization problem is said to have a low intrinsic dimensionality. Random Search is also embarrassingly parallel and additionally allows the inclusion of prior knowledge by specifying the distribution from which to sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hGXGQNxSr60",
        "outputId": "e04e1c15-c7c5-45cb-cc24-681e39b7f467"
      },
      "source": [
        "# Hyperparameter Optimization.\n",
        "\n",
        "# Number of trees in Random Forest.\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split.\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "# Maximum number of levels in the tree.\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000, 10)]\n",
        "# Minimum number of samples required to split a node.\n",
        "min_samples_split = [2, 3, 5, 7, 10, 14]\n",
        "# Minimum number of samples required at each leaf node.\n",
        "min_samples_leaf = [1, 2, 3, 4, 6, 7, 9]\n",
        "\n",
        "# Create the Random Grid.\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              'criterion':['entropy','gini']}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 5, 7, 10, 14], 'min_samples_leaf': [1, 2, 3, 4, 6, 7, 9], 'criterion': ['entropy', 'gini']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NluKNkGBWeIH",
        "outputId": "0919c763-46bf-4b82-a13f-b0baeccfff0c"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "clf = RandomForestClassifier()\n",
        "random_search = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, n_iter = 100, cv = 10, \n",
        "                                   verbose = 2, random_state = 100, n_jobs = -1)\n",
        "random_search = random_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   32.2s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed: 15.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 25.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9yyco_MYOXe",
        "outputId": "d1446aef-df43-4c6e-cddc-4365c77d92cd"
      },
      "source": [
        "best_random_grid = random_search.best_estimator_\n",
        "print(random_search.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=10, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=7, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndpwIB1vYhV1"
      },
      "source": [
        "y_pred = best_random_grid.predict(X_test)  # Predicting the test set results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMTNndY4Ycbt",
        "outputId": "22c89355-ec04-40cf-98aa-edf24a56a871"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7916666666666666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.92      0.86       130\n",
            "           1       0.76      0.52      0.62        62\n",
            "\n",
            "    accuracy                           0.79       192\n",
            "   macro avg       0.78      0.72      0.74       192\n",
            "weighted avg       0.79      0.79      0.78       192\n",
            "\n",
            "[[120  10]\n",
            " [ 30  32]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZED-7bdtJ1"
      },
      "source": [
        "The grid search approach is suitable when we are exploring relatively few combinations, like in the previous example, but when the hyperparameter search space is large enough, it is often preferable to use *RandomizedSearchCV* instead. This class can be used in much the same way as the *GridSearchCV* class, but instead of trying out all possible combinations, it evaluates a given number of random combinations by selecting a random value for each hyperparameter at every iteration. This approach has two main benefits:\n",
        "\n",
        "*   If we let the randomized search run for, say, 1,000 iterations, this approach will explore 1,000 different values for each hyperparameter (instead of just a few values per hyperparameter with the grid search approach).\n",
        "*   By setting the number of iterations, we have more control over the computing budget we want to allocate to hyperparameter search.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTYL3tYmlvC8"
      },
      "source": [
        "# **Automated Hyperparameter Tuning**\n",
        "\n",
        "1.   [Bayesian Optimization](https://en.wikipedia.org/wiki/Bayesian_optimization)\n",
        "2.   [Gradient-based Optimization](http://adl.stanford.edu/aa222/Lecture_Notes_files/AA222-Lecture3.pdf)\n",
        "3.   [Evolutionary Optimization](https://en.wikipedia.org/wiki/Evolutionary_algorithm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV6DoPbWygg1"
      },
      "source": [
        "# **Bayesian Optimization**\n",
        "\n",
        "**[Bayesian Optimization](https://github.com/fmfn/BayesianOptimization)** is a global optimization method for noisy black-box functions. Applied to hyperparameter optimization, Bayesian Optimization builds a probabilistic model of the function mapping from hyperparameter values to the objective evaluated on a validation set. By iteratively evaluating a promising hyperparameter configuration based on the current model, and then updating it, Bayesian optimization aims to gather observations revealing as much information as possible about this function and, in particular, the location of the optimum. It tries to balance exploration (hyperparameters for which the outcome is most uncertain) and exploitation (hyperparameters expected close to the optimum). In practice, Bayesian optimization has been shown to obtain better results in fewer evaluations compared to grid search and random search, due to the ability to reason about the quality of experiments before they are run.\n",
        "\n",
        "[Hyperopt: Distributed Hyperparameter Optimization](https://github.com/hyperopt/hyperopt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kl2O7WIenPW"
      },
      "source": [
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEKe1tp-m1Bq",
        "outputId": "54856bc0-9a87-480b-e541-ca90fae19bcb"
      },
      "source": [
        "space = {'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
        "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
        "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
        "        'min_samples_split' : hp.uniform ('min_samples_split', 0, 1),\n",
        "        'n_estimators' : hp.choice('n_estimators', [10, 50, 300, 750, 1200,1300,1500])}\n",
        "\n",
        "space"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': <hyperopt.pyll.base.Apply at 0x7fad40e1cad0>,\n",
              " 'max_depth': <hyperopt.pyll.base.Apply at 0x7fad40e1cd10>,\n",
              " 'max_features': <hyperopt.pyll.base.Apply at 0x7fad40e1ce50>,\n",
              " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x7fad40e1a150>,\n",
              " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x7fad40e1a2d0>,\n",
              " 'n_estimators': <hyperopt.pyll.base.Apply at 0x7fad40e07f10>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glSMvPJ2nDuo"
      },
      "source": [
        "def objective(space):\n",
        "    model = RandomForestClassifier(criterion = space['criterion'], max_depth = space['max_depth'],\n",
        "                                  max_features = space['max_features'],\n",
        "                                  min_samples_leaf = space['min_samples_leaf'],\n",
        "                                  min_samples_split = space['min_samples_split'],\n",
        "                                  n_estimators = space['n_estimators'], \n",
        "                                  )\n",
        "    \n",
        "    accuracy = cross_val_score(model, X_train, y_train, cv = 10).mean()\n",
        "\n",
        "    # We aim to maximize accuracy, therefore we return it as a negative value.\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fib-7mcGnhuX",
        "outputId": "8e08e1bb-3e06-44ae-ca86-88a79f7003bc"
      },
      "source": [
        "trials = Trials()\n",
        "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 80, trials = trials)\n",
        "best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 80/80 [14:56<00:00, 11.20s/it, best loss: -0.7672413793103448]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 1,\n",
              " 'max_depth': 630.0,\n",
              " 'max_features': 2,\n",
              " 'min_samples_leaf': 0.07711270254887398,\n",
              " 'min_samples_split': 0.14180659281480618,\n",
              " 'n_estimators': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q0iBif_oCfQ",
        "outputId": "a2f888d8-6b75-4c88-9bfd-c19ff48fd2be"
      },
      "source": [
        "crit = {0: 'entropy', 1: 'gini'}\n",
        "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
        "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200, 5: 1300, 6: 1500}\n",
        "\n",
        "print(crit[best['criterion']])\n",
        "print(feat[best['max_features']])\n",
        "print(est[best['n_estimators']])\n",
        "print(best['min_samples_leaf'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gini\n",
            "log2\n",
            "1500\n",
            "0.07711270254887398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeqP4vjwn8WR"
      },
      "source": [
        "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], max_depth = best['max_depth'], max_features = feat[best['max_features']], \n",
        "                                       min_samples_leaf = best['min_samples_leaf'], min_samples_split = best['min_samples_split'], \n",
        "                                       n_estimators = est[best['n_estimators']]).fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN0v5TKcoeyt"
      },
      "source": [
        "y_pred = trainedforest.predict(X_test)  # Predicting the test set results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBINmR0HorZH",
        "outputId": "b317f484-ad24-41a0-b450-5143c490106c"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7708333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.91      0.84       130\n",
            "           1       0.71      0.48      0.58        62\n",
            "\n",
            "    accuracy                           0.77       192\n",
            "   macro avg       0.75      0.70      0.71       192\n",
            "weighted avg       0.76      0.77      0.76       192\n",
            "\n",
            "[[118  12]\n",
            " [ 32  30]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZnJplLQ0WDe"
      },
      "source": [
        "# **TPOT - Automated Machine Learning for Supervised Classification Tasks.**\n",
        "\n",
        "[TPOTClassifier](http://epistasislab.github.io/tpot/api/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiRmzWlS1f6S",
        "outputId": "0ff4ae0c-e193-4999-d07b-d145ba5e046f"
      },
      "source": [
        "# Hyperparameter Optimization.\n",
        "\n",
        "# Number of trees in Random Forest.\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split.\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "# Maximum number of levels in the tree.\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000, 10)]\n",
        "# Minimum number of samples required to split a node.\n",
        "min_samples_split = [2, 3, 5, 7, 10, 14]\n",
        "# Minimum number of samples required at each leaf node.\n",
        "min_samples_leaf = [1, 2, 3, 4, 6, 7, 9]\n",
        "\n",
        "# Create the Random Grid.\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              'criterion':['entropy','gini']}\n",
        "\n",
        "print(random_grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [100, 311, 522, 733, 944, 1155, 1366, 1577, 1788, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 5, 7, 10, 14], 'min_samples_leaf': [1, 2, 3, 4, 6, 7, 9], 'criterion': ['entropy', 'gini']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wom04b2A3Wa6"
      },
      "source": [
        "!pip install tpot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263,
          "referenced_widgets": [
            "bea05d72077946bd85341606a6167bcf",
            "4c1736d7b97a4d7990b45b95889e9afa",
            "401051a0b8544e15877fca09e4ef46ed",
            "804d1cf3b44f446093239c32ab558f76",
            "792908175e804b3d8ee4d1644ce9af5a",
            "3e6d938608bc4570a4dc65cc5e68d089",
            "624099d88b79485c935e2840c842faf8",
            "5ba1b10fc68f43a6b1f6e69a953c45d9"
          ]
        },
        "id": "XJ5uifXn2RM9",
        "outputId": "230e6c5e-1a07-45d4-9859-d6df4a248a0b"
      },
      "source": [
        "from tpot import TPOTClassifier\n",
        "\n",
        "tpot_classifier = TPOTClassifier(generations= 5, population_size = 24, offspring_size = 12,\n",
        "                                 verbosity = 2, early_stop = 12, \n",
        "                                 config_dict = {'sklearn.ensemble.RandomForestClassifier': random_grid}, \n",
        "                                 cv = 10, scoring = 'accuracy').fit(X_train,y_train)\n",
        "\n",
        "accuracy = tpot_classifier.score(X_test, y_test)\n",
        "print(\"Accuracy is\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bea05d72077946bd85341606a6167bcf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=84.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.7655172413793104\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.7655172413793104\n",
            "\n",
            "Generation 3 - Current best internal CV score: 0.7655172413793104\n",
            "\n",
            "Generation 4 - Current best internal CV score: 0.7655172413793104\n",
            "\n",
            "Generation 5 - Current best internal CV score: 0.7655172413793104\n",
            "\n",
            "Best pipeline: RandomForestClassifier(input_matrix, criterion=gini, max_depth=1000, max_features=auto, min_samples_leaf=4, min_samples_split=7, n_estimators=100)\n",
            "Accuracy is 0.7864583333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixdw1D_cFk25"
      },
      "source": [
        "# **Optimize hyperparameters of the Model using Optuna**\n",
        "\n",
        "[Optuna: Automate Hyperparameter Tuning](https://optuna.org/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tW3HudgGBJ2"
      },
      "source": [
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNATIu4THXX5"
      },
      "source": [
        "The hyperparameters of the above algorithm are n_estimators and max_depth for which we can try different values to see if the model accuracy can be improved. The objective function is modified to accept a trial object. This trial has several methods for sampling hyperparameters. We create a study to run the hyperparameter optimization and finally read the best hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx5r_m--GL1u"
      },
      "source": [
        "import optuna\n",
        "import sklearn.svm\n",
        "def objective(trial):\n",
        "    classifier = trial.suggest_categorical('classifier', ['RandomForest', 'SVC'])\n",
        "    if classifier == 'RandomForest':\n",
        "        n_estimators = trial.suggest_int('n_estimators', 200, 2000, 10)\n",
        "        max_depth = int(trial.suggest_float('max_depth', 10, 100, log=True))\n",
        "        clf = sklearn.ensemble.RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth)\n",
        "    else:\n",
        "        c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
        "        clf = sklearn.svm.SVC(C=c, gamma='auto')\n",
        "    return sklearn.model_selection.cross_val_score(\n",
        "        clf, X_train, y_train, n_jobs=-1, cv=10).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxGp812rHbU2"
      },
      "source": [
        "study = optuna.create_study(direction = 'maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best Hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7A4DDugH06N",
        "outputId": "e34cb824-77e2-4899-bf9a-9ee1d9171899"
      },
      "source": [
        "print(trial)\n",
        "print(study.best_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FrozenTrial(number=40, values=[0.7602540834845736], datetime_start=datetime.datetime(2021, 6, 4, 8, 31, 35, 923379), datetime_complete=datetime.datetime(2021, 6, 4, 8, 31, 45, 869130), params={'classifier': 'RandomForest', 'n_estimators': 680, 'max_depth': 31.692229644149506}, distributions={'classifier': CategoricalDistribution(choices=('RandomForest', 'SVC')), 'n_estimators': IntUniformDistribution(high=2000, low=200, step=10), 'max_depth': LogUniformDistribution(high=100.0, low=10.0)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=40, state=TrialState.COMPLETE, value=None)\n",
            "{'classifier': 'RandomForest', 'n_estimators': 680, 'max_depth': 31.692229644149506}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yaLJKOGH_zr"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=330, max_depth=30).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgVQo2duIUYV"
      },
      "source": [
        "y_pred = clf.predict(X_test)  # Predicting the test set results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmcRt2uJIUYe",
        "outputId": "f782c53a-b287-47af-cc06-814f0b044bcb"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score 0.7864583333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       130\n",
            "           1       0.71      0.58      0.64        62\n",
            "\n",
            "    accuracy                           0.79       192\n",
            "   macro avg       0.76      0.73      0.74       192\n",
            "weighted avg       0.78      0.79      0.78       192\n",
            "\n",
            "[[115  15]\n",
            " [ 26  36]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzIyXCmuK2r8"
      },
      "source": [
        "# **[Tuning a scikit-learn estimator with Skopt](https://scikit-optimize.github.io/stable/auto_examples/hyperparameter-optimization.html)**"
      ]
    }
  ]
}